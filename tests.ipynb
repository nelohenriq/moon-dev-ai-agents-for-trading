{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Base URL for Solana RPC endpoint\n",
    "rpc_url = \"https://api.mainnet-beta.solana.com\"\n",
    "\n",
    "# List of wallet addresses holding some tokens (example)\n",
    "wallet_addresses = [\n",
    "    'C4su4UzsPgbDApTEWFThKwbTyHE9ZoRnV7TXwrtL55SB',\n",
    "    'AnsWpQ5KzJpns4fTXQWzWg8YakJMrDS2T6M3TpUX4t5U',\n",
    "    '93AX7iJUTbzmzB4vHXCRHjfLyrskAfNd1ReRQkfRUnXL',\n",
    "    # Add more wallet addresses...\n",
    "]\n",
    "\n",
    "def get_token_accounts_by_owner(wallet_address):\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "    payload = {\n",
    "        \"jsonrpc\": \"2.0\",\n",
    "        \"id\": 1,\n",
    "        \"method\": \"getTokenAccountsByOwner\",\n",
    "        \"params\": [\n",
    "            wallet_address,\n",
    "            {\n",
    "                \"programId\": \"TokenkegQfeZyiNwAJbNbGKPFXCWuBvf9Ss623VQ5DA\",\n",
    "                \"encoding\": \"jsonParsed\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    response = requests.post(rpc_url, json=payload, headers=headers)\n",
    "    return response.json()\n",
    "\n",
    "# Loop through each wallet and retrieve their token accounts\n",
    "wallet_to_mints = {}\n",
    "\n",
    "for wallet in wallet_addresses:\n",
    "    accounts = get_token_accounts_by_owner(wallet)\n",
    "    # Extract mint addresses for each wallet\n",
    "    mints = [account['account']['data']['parsed']['info']['mint'] for account in accounts.get('result', {}).get('value', [])]\n",
    "    \n",
    "    # Store the mint addresses for each wallet\n",
    "    wallet_to_mints[wallet] = mints\n",
    "\n",
    "# Print the mint addresses associated with each wallet\n",
    "print(wallet_to_mints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import nest_asyncio\n",
    "from solana.rpc.async_api import AsyncClient\n",
    "from solana.rpc.api import Pubkey\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "async def get_wallet_transactions(wallet_address, limit=10):\n",
    "    pubkey = Pubkey.from_string(wallet_address)\n",
    "    async with AsyncClient(\"https://api.mainnet-beta.solana.com\") as client:\n",
    "        # Fetch the signatures for the wallet address\n",
    "        signatures_response = await client.get_signatures_for_address(pubkey, limit=limit)\n",
    "\n",
    "        # Check if the response contains 'value' and that it's a list\n",
    "        if not hasattr(signatures_response, 'value') or not isinstance(signatures_response.value, list):\n",
    "            return []  # Return an empty list if no 'value' or incorrect format\n",
    "\n",
    "        # Extract signatures from the response\n",
    "        transaction_signatures = [sig.signature for sig in signatures_response.value]\n",
    "\n",
    "        # Fetch the transaction details using get_transaction (instead of get_parsed_transactions)\n",
    "        transactions = []\n",
    "        for signature in transaction_signatures:\n",
    "            transaction = await client.get_transaction(signature, \"jsonParsed\", max_supported_transaction_version=0)\n",
    "            transactions.append(transaction)\n",
    "\n",
    "        return transactions\n",
    "\n",
    "async def main():\n",
    "    wallet_address = \"BHcTB516BrHzqDyFjMnDfWhSdLLxKKbihf4RauCJtD1h\"\n",
    "    transactions = await get_wallet_transactions(wallet_address)\n",
    "    for tx in transactions:\n",
    "        await asyncio.sleep(0.5)\n",
    "        print(f\"Signature: {tx.transaction.signatures[0]}\")\n",
    "        print(f\"Timestamp: {tx.block_time}\")\n",
    "        print(\"Instructions:\")\n",
    "        for instruction in tx.transaction.message.instructions:\n",
    "            print(f\"  Program: {instruction.program_id}\")\n",
    "        print(\"-\" * 20)\n",
    "\n",
    "asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import requests\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from pprint import pprint\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# RPC Endpoint\n",
    "RPC_ENDPOINT = os.getenv(\"RPC_ENDPOINT\")\n",
    "\n",
    "# Fetch token holders using getTokenLargestAccounts\n",
    "def get_token_holders(token_address):\n",
    "    payload = {\n",
    "        \"jsonrpc\": \"2.0\",\n",
    "        \"id\": \"getTokenLargestAccounts\",\n",
    "        \"method\": \"getTokenLargestAccounts\",\n",
    "        \"params\": [token_address],\n",
    "    }\n",
    "    response = requests.post(RPC_ENDPOINT, json=payload)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json().get(\"result\", {}).get(\"value\", [])\n",
    "        pprint(data)\n",
    "        return [(holder[\"address\"], float(holder[\"amount\"])) for holder in data]\n",
    "    return []\n",
    "    \n",
    "tokens = [\"BbzVAbu8rrmEGQRSFhS2tF42Agp1FsBtcEMoYLH3r84J\",\n",
    "\"BBBmxremG7CnQCg1BpArvEY5QPH1J7fydn68fNKMcZne\",\n",
    "\"7zaAmppPP7tstHMBqvrsy5J11ZGS2BkGbHv2xey5iNBo\",\n",
    "\"CtQ7hnCGqLmFeW87tom2fHGTsCraTjzogjzALQLykXqL\",\n",
    "\"DLktwpXUh9ydTGxcZRvkESJFggLiezu2VFP72dapump\",\n",
    "\"6cfZ9tJhfsR7bZfVWAPtu2UrPqfWomud67Q2RC5Ypump\",\n",
    "\"FnJoStz95yP5B9kSg2BiCE8FdsiL4S2AnZLrtMJYBdHg\",\n",
    "\"9NcdSJeMvgMYpFgKJGrJyBqMTkWDApzZv7kwFiFpnWMy\",\n",
    "\"4Sk8TVAoWaCPET62MRGsuKi8e2VwyAgtbiHS1MxP7vcn\",\n",
    "\"FBmV4Zp3YiXSaybUKV6Dnh5W489cmQCRbnBiUnEwmoon\"\n",
    "]\n",
    "for token in tokens:\n",
    "    holders = get_token_holders(token)\n",
    "    print(f\"Token: {token}\")\n",
    "    print(\"Holders:\")\n",
    "    for holder, amount in holders:\n",
    "        print(f\"  {holder}: {amount}\")\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "RPC_ENDPOINT = \"https://api.mainnet-beta.solana.com\"\n",
    "\n",
    "def get_token_accounts_by_owner(wallet_address):\n",
    "    payload = {\n",
    "        \"jsonrpc\": \"2.0\",\n",
    "        \"id\": 1,\n",
    "        \"method\": \"getTokenAccountsByOwner\",\n",
    "        \"params\": [\n",
    "            wallet_address,\n",
    "            {\"programId\": \"TokenkegQfeZyiNwAJbNbGKPFXCWuBvf9Ss623VQ5DA\"},\n",
    "            {\"encoding\": \"jsonParsed\"}\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(RPC_ENDPOINT, json=payload, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        data = response.json().get(\"result\", {}).get(\"value\", [])\n",
    "\n",
    "        # Extract mints\n",
    "        mints = [account[\"account\"][\"data\"][\"parsed\"][\"info\"][\"mint\"] for account in data]\n",
    "        return mints\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching token accounts: {e}\")\n",
    "        return []\n",
    "\n",
    "# Example usage\n",
    "wallet_address = \"EA2giVUJRAmxL4K9NHydnDsXTNqtFxXMfW5mzSWVANrh\"\n",
    "tokens = get_token_accounts_by_owner(wallet_address)\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import time\n",
    "from typing import Union, List, Optional\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "class RunRPCMethod:\n",
    "    BASE_URL = \"https://mainnet.helius-rpc.com\"\n",
    "\n",
    "    def __init__(self, max_retries: int = 3, initial_delay: int = 1):\n",
    "        self.api_key = os.getenv(\"HELIUS_API_KEY\")\n",
    "        if not self.api_key:\n",
    "            raise ValueError(\"HELIUS_API_KEY not found in .env file\")\n",
    "\n",
    "        self.max_retries = max_retries\n",
    "        self.initial_delay = initial_delay\n",
    "\n",
    "    @property\n",
    "    def rpc_url(self) -> str:\n",
    "        return f\"{self.BASE_URL}/?api-key={self.api_key}\"\n",
    "\n",
    "    def _make_api_request(self, payload: dict):\n",
    "        \"\"\"Make API requests with exponential backoff.\"\"\"\n",
    "        delay = self.initial_delay\n",
    "        for attempt in range(self.max_retries):\n",
    "            try:\n",
    "                response = requests.post(self.rpc_url, json=payload, headers={\"Content-Type\": \"application/json\"}, timeout=10)\n",
    "                response.raise_for_status()\n",
    "                return response.json()\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                if attempt == self.max_retries - 1:\n",
    "                    print(f\"Max retries reached. Failed request: {payload}\")\n",
    "                    raise e\n",
    "                print(f\"Attempt {attempt + 1} failed. Retrying in {delay} seconds...\")\n",
    "                time.sleep(delay)\n",
    "                delay *= 2  # Exponential backoff\n",
    "\n",
    "    def call(self, method: str, request_id: Union[int, str], params: Optional[List] = None):\n",
    "        \"\"\"Generic method to call any Solana RPC method with retries.\"\"\"\n",
    "        payload = {\n",
    "            \"jsonrpc\": \"2.0\",  # Hardcoded constant\n",
    "            \"id\": request_id,\n",
    "            \"method\": method,\n",
    "            \"params\": params or []\n",
    "        }\n",
    "        return self._make_api_request(payload)\n",
    "\n",
    "    # Predefined methods for common RPC calls\n",
    "    def get_account_info(self, request_id: Union[int, str], account: str, encoding: str = \"jsonParsed\"):\n",
    "        \"\"\"Fetch account info from Solana blockchain.\"\"\"\n",
    "        return self.call(\"getAccountInfo\", request_id, [{\"encoding\": encoding, \"account\": account}])\n",
    "\n",
    "    def get_block_height(self, request_id: Union[int, str]):\n",
    "        \"\"\"Fetch the current block height.\"\"\"\n",
    "        return self.call(\"getBlockHeight\", request_id)\n",
    "\n",
    "    def get_recent_blockhash(self, request_id: Union[int, str]):\n",
    "        \"\"\"Fetch the most recent blockhash.\"\"\"\n",
    "        return self.call(\"getRecentBlockhash\", request_id)\n",
    "\n",
    "    def get_transaction(self, request_id: Union[int, str], signature: str, encoding: str = \"json\"):\n",
    "        \"\"\"Fetch transaction details by signature.\"\"\"\n",
    "        return self.call(\"getTransaction\", request_id, [signature, {\"encoding\": encoding}])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rom rpc_client import RunRPCMethod\n",
    "\n",
    "# Initialize the RPC client\n",
    "rpc = RunRPCMethod()\n",
    "\n",
    "# Make calls using predefined methods\n",
    "try:\n",
    "    account_info = rpc.get_account_info(request_id=\"account_info\", account=\"2aoZTcWvDZKeyufWkYbJ9mYaoSD1P9HPKzEcZ79GZHbx\")\n",
    "\n",
    "    block_height = rpc.get_block_height(request_id=\"block_1\")\n",
    "    print(\"Block Height:\", block_height)\n",
    "\n",
    "    recent_blockhash = rpc.get_recent_blockhash(request_id=\"blockhash_abc\")\n",
    "    print(\"Recent Blockhash:\", recent_blockhash)\n",
    "\n",
    "    transaction_info = rpc.get_transaction(request_id=\"txn_456\", signature=\"QBcTdN1VuSVffWzPXpnzN6t8UZXZe3Gm16pAaTuhSQkXfeDvWzVhhzZWevuhA7pNb4Cgmm6kLjBUAwiX7YAQcAC\")\n",
    "    print(\"Transaction Info:\", transaction_info)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import websockets\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import json\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "HELIUS_WS_URL = \"wss://mainnet.helius-rpc.com/?api-key=cde2166e-a9cc-4f20-aab6-931319852b4a\"\n",
    "\n",
    "async def listen_helius():\n",
    "    async with websockets.connect(HELIUS_WS_URL) as ws:\n",
    "        mint_subscription = {\n",
    "            \"jsonrpc\": \"2.0\",\n",
    "            \"id\": 1,\n",
    "            \"method\": \"logsSubscribe\",\n",
    "            \"params\": [\n",
    "                {\n",
    "                    \"mentions\": [\"TokenkegQfeZyiNwAJbNbGKPFXCWuBvf9Ss623VQ5DA\"]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        raydium_subscription = {\n",
    "            \"jsonrpc\": \"2.0\",\n",
    "            \"id\": 2,\n",
    "            \"method\": \"logsSubscribe\",\n",
    "            \"params\": [\n",
    "                {\n",
    "                    \"mentions\": [\"675kPX9MHTjS2zt1qfr1NYHuzeLXfQM9H24wFSUt1Mp8\"]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "\n",
    "        await ws.send(json.dumps(mint_subscription))\n",
    "        await ws.send(json.dumps(raydium_subscription))\n",
    "        print(\"Listening for token mints & Raydium pool creations with enhanced anti-Rug and frontrun checks...\")\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "                message = await ws.recv()\n",
    "                print(message)\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(listen_helius())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "DEX_SCREENER_API = \"https://api.dexscreener.com/latest/dex/tokens/\"\n",
    "\n",
    "def analyze_token_metrics(token_address):\n",
    "    \"\"\"Fetches and analyzes token liquidity, volume, and holders.\"\"\"\n",
    "    url = f\"{DEX_SCREENER_API}{token_address}\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            data = response.json().get(\"pairs\", [])\n",
    "\n",
    "            if not data:\n",
    "                print(f\"⚠️ No valid data returned for {token_address}\")\n",
    "                return None\n",
    "\n",
    "            # You can customize this if you need to analyze multiple pairs.\n",
    "            pair_data = data[0]  # Default to the first pair (you can adjust this logic)\n",
    "\n",
    "            # Check for Raydium filter\n",
    "            dex = pair_data.get(\"dexId\", \"Unknown\")  # Default to \"Unknown\" if not found\n",
    "            if dex.lower() != \"raydium\":\n",
    "                print(\n",
    "                    f\"⚠️ Token {token_address} is not a Raydium token, skipping analysis.\"\n",
    "                )\n",
    "                return None\n",
    "\n",
    "            analysis = {\n",
    "                \"symbol\": pair_data.get(\"baseToken\", {}).get(\"symbol\", \"N/A\"),\n",
    "                \"token_address\": token_address,\n",
    "                \"liquidity\": pair_data.get(\"liquidity\", 0),  # Default to 0 if not found\n",
    "                \"volume_24h\": pair_data.get(\"volume\", {}).get(\n",
    "                    \"h24\", 0\n",
    "                ),  # Default to 0 if not found\n",
    "                \"holders\": pair_data.get(\"holders\", 0),  # Default to 0 if not found\n",
    "                \"dex\": dex,\n",
    "                \"social_links\": pair_data.get(\"info\", {}).get(\n",
    "                    \"socials\", []\n",
    "                ),  # Default to empty list if not found\n",
    "            }\n",
    "\n",
    "            # You could add more pairs or different fields here if needed\n",
    "            return analysis\n",
    "        else:\n",
    "            print(\n",
    "                f\"⚠️ Failed to fetch token data for {token_address} - Status code: {response.status_code}\"\n",
    "            )\n",
    "            return None\n",
    "\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"❌ Error fetching token data for {token_address}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = analyze_token_metrics(\"DZaBTefhyzqdaNX6FyGAyUwpAAEeZeXgqw5FsHTkDciA\")\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "chainId = \"solana\"\n",
    "tokenAddress = \"6dPgBkXgWHmrH41zRVYtGrqAT4wAAertU3RjbiZJB4X8\"\n",
    "\n",
    "response = requests.get(\n",
    "    \"https://api.dexscreener.com/token-pairs/v1/{chainId}/{tokenAddress}\",\n",
    ")\n",
    "\n",
    "data = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import requests\n",
    "\n",
    "TOKEN_PROGRAM_ID = \"TokenkegQfeZyiNwAJbNbGKPFXCWuBvf9Ss623VQ5DA\"\n",
    "RPC_ENDPOINT=\"https://mainnet.helius-rpc.com/?api-key=cde2166e-a9cc-4f20-aab6-931319852b4a\"\n",
    "\n",
    "\n",
    "def get_new_token_mints():\n",
    "    \"\"\"Fetch newly minted Solana SPL tokens using Helius RPC, excluding non-token program transactions.\"\"\"\n",
    "\n",
    "    # Initialize a set to keep track of seen transactions\n",
    "    seen_transactions = set()\n",
    "\n",
    "    url = RPC_ENDPOINT\n",
    "    current_time = int(time.time())\n",
    "    one_hour_ago = current_time - 3600  # One hour ago in Unix timestamp\n",
    "\n",
    "    # Define the list of program IDs to be excluded\n",
    "    excluded_program_ids = [\n",
    "        \"So11111111111111111111111111111111111111112\",  # Solana System Program ID\n",
    "        \"JUPyiwrYJFskUPiHa7hkeR8VUtAeFoSYbKedZNsDvCN\",  # Example non-token program\n",
    "        \"EPjFWdd5AufqSSqeM2qN1xzybapC8G4wEGGkZwyTDt1v\",  # Another example non-token program\n",
    "        \"11111111111111111111111111111111\",  # Example non-token program\n",
    "        # Add other program IDs you want to exclude\n",
    "    ]\n",
    "\n",
    "    response = requests.post(\n",
    "        url,\n",
    "        json={\n",
    "            \"jsonrpc\": \"2.0\",\n",
    "            \"id\": 1,\n",
    "            \"method\": \"getSignaturesForAddress\",\n",
    "            \"params\": [\n",
    "                TOKEN_PROGRAM_ID,  # Track transactions for Token Program\n",
    "                {\"limit\": 20},  # Fetch latest 20 transactions\n",
    "            ],\n",
    "        },\n",
    "    )\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(f\"❌ Error fetching transactions: {response.status_code}\")\n",
    "        return []\n",
    "\n",
    "    transactions = response.json().get(\"result\", [])\n",
    "    new_tokens = []\n",
    "\n",
    "    for tx in transactions:\n",
    "        sig = tx[\"signature\"]\n",
    "\n",
    "        if tx[\"blockTime\"] > one_hour_ago:\n",
    "            break  # Stop processing if we've reached transactions older than one hour\n",
    "\n",
    "        if sig in seen_transactions:  # Avoid duplicate processing\n",
    "            continue\n",
    "\n",
    "        seen_transactions.add(sig)  # Mark transaction as processed\n",
    "\n",
    "        # Fetch transaction details\n",
    "        tx_response = requests.post(\n",
    "            url,\n",
    "            json={\n",
    "                \"jsonrpc\": \"2.0\",\n",
    "                \"id\": 1,\n",
    "                \"method\": \"getTransaction\",\n",
    "                \"params\": [\n",
    "                    sig,\n",
    "                    {\"maxSupportedTransactionVersion\": 0},\n",
    "                ],  # Get parsed transaction details\n",
    "            },\n",
    "        )\n",
    "\n",
    "        if tx_response.status_code != 200:\n",
    "            print(f\"⚠️ Error fetching transaction {sig}: {tx_response.status_code}\")\n",
    "            continue\n",
    "\n",
    "        tx_data = tx_response.json().get(\"result\", {})\n",
    "\n",
    "        # Check if the transaction involves any excluded program IDs\n",
    "        if \"meta\" in tx_data and tx_data[\"meta\"].get(\"err\") is None:\n",
    "            if \"postTokenBalances\" in tx_data[\"meta\"]:\n",
    "                for balance_change in tx_data[\"meta\"][\"postTokenBalances\"]:\n",
    "                    mint_address = balance_change[\"mint\"]\n",
    "\n",
    "                    # Exclude transactions involving unwanted program IDs\n",
    "                    if any(\n",
    "                        mint_address == excluded_program_id\n",
    "                        for excluded_program_id in excluded_program_ids\n",
    "                    ):\n",
    "                        continue\n",
    "\n",
    "                    # Ensure mint address is unique\n",
    "                    if mint_address not in [t[\"mint_address\"] for t in new_tokens]:\n",
    "                        new_tokens.append(\n",
    "                            {\n",
    "                                \"mint_address\": mint_address,\n",
    "                                \"created_at\": tx.get(\"blockTime\", time.time()),\n",
    "                            }\n",
    "                        )\n",
    "\n",
    "    return new_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_new_token_mints()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import websockets\n",
    "import json\n",
    "import requests\n",
    "import redis\n",
    "import time\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Redis Setup\n",
    "redis_client = redis.Redis(host=\"localhost\", port=6379, db=0, decode_responses=True)\n",
    "\n",
    "# API Configurations\n",
    "HELIUS_RPC_URL = (\n",
    "    \"wss://mainnet.helius-rpc.com/?api-key=cde2166e-a9cc-4f20-aab6-931319852b4a\"\n",
    ")\n",
    "DEX_SCREENER_URL = \"https://api.dexscreener.com/latest/dex/tokens/solana\"\n",
    "\n",
    "# Solana Token Program ID (Used for tracking token mints)\n",
    "SPL_TOKEN_PROGRAM_ID = \"TokenkegQfeZyiNwAJbNbGKPFXCWuBvf9Ss623VQ5DA\"\n",
    "\n",
    "\n",
    "async def monitor_new_tokens():\n",
    "    \"\"\"Listens for new Solana token mints via Helius RPC.\"\"\"\n",
    "    async with websockets.connect(HELIUS_RPC_URL) as ws:\n",
    "        request = {\n",
    "            \"jsonrpc\": \"2.0\",\n",
    "            \"id\": 1,\n",
    "            \"method\": \"logsSubscribe\",\n",
    "            \"params\": [\n",
    "                {\"mentions\": [SPL_TOKEN_PROGRAM_ID]},\n",
    "                {\"commitment\": \"finalized\"},\n",
    "            ],\n",
    "        }\n",
    "        await ws.send(json.dumps(request))\n",
    "        print(\"🔍 Listening for new token mints...\")\n",
    "\n",
    "        while True:\n",
    "            response = await ws.recv()\n",
    "            data = json.loads(response)\n",
    "\n",
    "            if \"params\" in data and \"result\" in data[\"params\"]:\n",
    "                logs = data[\"params\"][\"result\"][\"value\"]\n",
    "                if any(\"MintTo\" in log for log in logs[\"logs\"]):\n",
    "                    print(\"🚀 New token mint detected!\")\n",
    "\n",
    "                    mint_info = extract_mint_info(logs)\n",
    "                    if mint_info and not redis_client.sismember(\n",
    "                        \"processed_tokens\", mint_info[\"mint_address\"]\n",
    "                    ):\n",
    "                        redis_client.sadd(\"processed_tokens\", mint_info[\"mint_address\"])\n",
    "                        print(f\"✅ Token Added: {mint_info}\")\n",
    "                        await check_dex_screener(mint_info)\n",
    "\n",
    "\n",
    "def extract_mint_info(logs):\n",
    "    \"\"\"Extracts the token mint address, authority, and other details.\"\"\"\n",
    "    try:\n",
    "        mint_address = logs[\"account\"]\n",
    "        mint_authority = logs.get(\"owner\", \"Unknown\")\n",
    "        return {\n",
    "            \"mint_address\": mint_address,\n",
    "            \"mint_authority\": mint_authority,\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error extracting mint info: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def fetch_dex_screener_tokens():\n",
    "    \"\"\"Fetches newly listed Solana tokens from DEX Screener API.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(DEX_SCREENER_URL)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            return data.get(\"pairs\", [])\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error fetching DEX Screener data: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "async def check_dex_screener(mint_info):\n",
    "    \"\"\"Checks if a newly minted token is listed on DEX Screener.\"\"\"\n",
    "    while True:\n",
    "        tokens = fetch_dex_screener_tokens()\n",
    "        for pair in tokens:\n",
    "            base_token = pair[\"baseToken\"]\n",
    "            if base_token[\"address\"] == mint_info[\"mint_address\"]:\n",
    "                liquidity = pair[\"liquidity\"][\"usd\"] if \"liquidity\" in pair else 0\n",
    "                volume = pair[\"volume\"][\"h24\"] if \"volume\" in pair else 0\n",
    "\n",
    "                if liquidity >= 10000:  # Only track tokens with at least $10K liquidity\n",
    "                    redis_client.sadd(\"listed_tokens\", mint_info[\"mint_address\"])\n",
    "                    print(\n",
    "                        f\"💰 Token Listed on DEX: {base_token['name']} ({base_token['symbol']})\"\n",
    "                    )\n",
    "                    print(f\"🔗 DEX Screener URL: {pair['url']}\")\n",
    "                    return\n",
    "\n",
    "        print(\"🔄 Checking DEX Screener again in 30s...\")\n",
    "        await asyncio.sleep(30)\n",
    "\n",
    "\n",
    "async def main():\n",
    "    await asyncio.gather(monitor_new_tokens())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import csv\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# Define the file path where the CSV will be saved\n",
    "file_path = 'src/agents/api_data/new_token_addresses_1.csv'\n",
    "\n",
    "# Ensure the directory exists, create it if it doesn't\n",
    "directory = os.path.dirname(file_path)\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# Dexscreener API endpoint for latest token profiles\n",
    "API_URL = \"https://api.dexscreener.com/token-profiles/latest/v1\"\n",
    "\n",
    "# Fetch the latest token profiles\n",
    "def get_latest_tokens():\n",
    "    response = requests.get(API_URL)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()  # Returns the latest token data\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Filter tokens to include only Solana tokens (chainId == \"solana\")\n",
    "def filter_solana_tokens(tokens):\n",
    "    solana_tokens = [token for token in tokens if token['chainId'] == 'solana']\n",
    "    return solana_tokens\n",
    "\n",
    "# Function to check if the token is already in the CSV file\n",
    "def is_token_duplicate(token_address):\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, mode='r', newline='') as file:\n",
    "            reader = csv.reader(file)\n",
    "            existing_tokens = [row[0] for row in reader]\n",
    "            if token_address in existing_tokens:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "# Generate CSV with token information\n",
    "def generate_csv(tokens):\n",
    "    # Open CSV file for writing (append mode)\n",
    "    with open(file_path, mode=\"a\", newline=\"\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        \n",
    "        # Write header only if the file is empty\n",
    "        if os.path.getsize(file_path) == 0:\n",
    "            writer.writerow([\"Token Address\", \"Time Found\", \"Epoch Time\", \"Solscan Link\", \"DexScreener Link\", \"Birdeye Link\"])\n",
    "        \n",
    "        # Loop through the Solana tokens and write the details\n",
    "        for token in tokens:\n",
    "            token_address = token[\"tokenAddress\"]\n",
    "            \n",
    "            # Check if the token already exists in the CSV file\n",
    "            if is_token_duplicate(token_address):\n",
    "                continue\n",
    "            \n",
    "            time_found = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            epoch_time = int(time.time())\n",
    "            \n",
    "            # Form the URLs\n",
    "            solscan_link = f\"https://solscan.io/tx/{token_address}\"\n",
    "            dexscreener_link = token[\"url\"]\n",
    "            birdeye_link = f\"https://birdeye.so/token/{token_address}?chain=solana\"\n",
    "            \n",
    "            # Write the token data to CSV\n",
    "            writer.writerow([token_address, time_found, epoch_time, solscan_link, dexscreener_link, birdeye_link])\n",
    "    \n",
    "    print(f\"CSV file '{file_path}' updated successfully!\")\n",
    "\n",
    "# Continuous monitoring loop\n",
    "def monitor_tokens():\n",
    "    while True:\n",
    "        print(\"Checking for new tokens...\")\n",
    "        latest_tokens = get_latest_tokens()\n",
    "        if latest_tokens:\n",
    "            # Filter for Solana tokens\n",
    "            solana_tokens = filter_solana_tokens(latest_tokens)\n",
    "            \n",
    "            # Generate CSV with the token information\n",
    "            generate_csv(solana_tokens)\n",
    "        \n",
    "        # Sleep for a desired interval before checking again (e.g., every 60 seconds)\n",
    "        time.sleep(10)\n",
    "\n",
    "# Start monitoring\n",
    "monitor_tokens()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/teamspace/studios/this_studio/moondev\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "import anthropic\n",
    "import openai\n",
    "from typing import Dict, List\n",
    "import time\n",
    "from termcolor import colored, cprint\n",
    "import random\n",
    "import src.config as config\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Fun emoji sets for different actions\n",
    "SPINNER_EMOJIS = [\"🌍\", \"🌎\", \"🌏\"]  # Earth spinning\n",
    "MOON_PHASES = [\"🌑\", \"🌒\", \"🌓\", \"🌔\", \"🌕\", \"🌖\", \"🌗\", \"🌘\"]  # Moon phases\n",
    "ROCKET_SEQUENCE = [\"🚀\", \"💫\", \"✨\", \"💫\", \"🌟\"]  # Rocket launch\n",
    "ERROR_EMOJIS = [\"💥\", \"🚨\", \"⚠️\", \"❌\", \"🔥\"]  # Error indicators\n",
    "SUCCESS_EMOJIS = [\"✨\", \"🎯\", \"🎨\", \"🎪\", \"🎭\", \"🎪\"]  # Success indicators\n",
    "\n",
    "COINGECKO_API_KEY = os.getenv(\"COINGECKO_API_KEY\")\n",
    "BASE_URL = \"https://api.coingecko.com/api/v3\"\n",
    "RESULTS_DIR = Path(\"/teamspace/studios/this_studio/moondev/src/data/coingecko_results\")\n",
    "NEW_COINS_FILE = RESULTS_DIR / \"new_coins.csv\"\n",
    "DELAY_BETWEEN_REQUESTS = 1\n",
    "\n",
    "def print_spinner(\n",
    "    message: str, emoji_set: List[str], color: str = \"white\", bg_color: str = \"on_blue\"\n",
    "):\n",
    "    \"\"\"Print a spinning emoji animation with message\"\"\"\n",
    "    for emoji in emoji_set:\n",
    "        print(f\"\\r{emoji} {colored(message, color, bg_color)}\", end=\"\", flush=True)\n",
    "        time.sleep(0.2)\n",
    "    print()  # New line after animation\n",
    "\n",
    "\n",
    "def print_fancy(\n",
    "    message: str,\n",
    "    color: str = \"white\",\n",
    "    bg_color: str = \"on_blue\",\n",
    "    emojis: List[str] = None,\n",
    "):\n",
    "    \"\"\"Print a message with random emojis from set\"\"\"\n",
    "    if emojis:\n",
    "        emoji = random.choice(emojis)\n",
    "        cprint(f\"{emoji} {message} {emoji}\", color, bg_color)\n",
    "    else:\n",
    "        cprint(message, color, bg_color)\n",
    "\n",
    "def get_new_coins() -> pd.DataFrame:\n",
    "        \"\"\"Get latest coins using the free simple markets endpoint\"\"\"\n",
    "        try:\n",
    "            print_spinner(\"Scanning for new coins...\", MOON_PHASES, \"yellow\", \"on_blue\")\n",
    "            response = requests.get(\n",
    "                f\"{BASE_URL}/coins/markets\",\n",
    "                params={\n",
    "                    \"vs_currency\": \"usd\",\n",
    "                    \"order\": \"volume_desc\",  # High volume coins\n",
    "                    \"per_page\": 250,\n",
    "                    \"page\": 1,\n",
    "                    \"sparkline\": False,\n",
    "                },\n",
    "            )\n",
    "\n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                df = pd.DataFrame(data)\n",
    "                df[\"timestamp\"] = datetime.now().isoformat()\n",
    "                df[\"coingecko_url\"] = df[\"id\"].apply(\n",
    "                    lambda x: f\"https://www.coingecko.com/en/coins/{x}\"\n",
    "                )\n",
    "                df.to_csv(NEW_COINS_FILE, index=False)\n",
    "\n",
    "                print_fancy(\n",
    "                    f\"🎯 Found {len(df)} active tokens!\",\n",
    "                    \"cyan\",\n",
    "                    \"on_grey\",\n",
    "                    SUCCESS_EMOJIS,\n",
    "                )\n",
    "                return df\n",
    "\n",
    "            else:\n",
    "                print_fancy(\n",
    "                    f\"Error fetching coins: {response.text}\",\n",
    "                    \"white\",\n",
    "                    \"on_red\",\n",
    "                    ERROR_EMOJIS,\n",
    "                )\n",
    "                return pd.DataFrame()\n",
    "\n",
    "        except Exception as e:\n",
    "            print_fancy(f\"Error: {str(e)}\", \"white\", \"on_red\", ERROR_EMOJIS)\n",
    "            return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🌘 \u001b[44m\u001b[33mScanning for new coins...\u001b[0m\n",
      "\u001b[40m\u001b[36m🎯 🎯 Found 250 active tokens! 🎯\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "new_coins = get_new_coins()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
